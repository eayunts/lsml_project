{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple example of transfer learning from pretrained model using PyTorch.**\n",
    "* Metrics: f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  gconf-service gconf-service-backend gconf2 gconf2-common libbonobo2-0\n",
      "  libbonobo2-common libgconf-2-4 libgnome-2-0 libgnome2-common libgnomevfs2-0\n",
      "  libgnomevfs2-common libllvm3.8 libmircommon5 liborbit-2-0 libqmi-glib1\n",
      "  linux-headers-4.4.0-47 linux-headers-4.4.0-47-generic linux-headers-4.4.0-53\n",
      "  linux-headers-4.4.0-53-generic linux-image-4.4.0-47-generic\n",
      "  linux-image-4.4.0-53-generic linux-image-extra-4.4.0-47-generic\n",
      "  linux-image-extra-4.4.0-53-generic snap-confine\n",
      "Use 'sudo apt autoremove' to remove them.\n",
      "The following additional packages will be installed:\n",
      "  libcuda1-418 nvidia-418 nvidia-418-dev nvidia-opencl-icd-418\n",
      "The following packages will be REMOVED:\n",
      "  libcuda1-367 libcuda1-387 nvidia-367 nvidia-367-dev nvidia-387\n",
      "  nvidia-387-dev nvidia-opencl-icd-361 nvidia-opencl-icd-367\n",
      "  nvidia-opencl-icd-387\n",
      "The following NEW packages will be installed:\n",
      "  libcuda1-418 nvidia-418 nvidia-418-dev nvidia-opencl-icd-418\n",
      "The following packages will be upgraded:\n",
      "  cuda-drivers\n",
      "1 upgraded, 4 newly installed, 9 to remove and 3 not upgraded.\n",
      "Need to get 112 MB of archives.\n",
      "After this operation, 157 MB of additional disk space will be used.\n",
      "Get:1 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-drivers 418.67-1 [2,404 B]\n",
      "Get:2 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  nvidia-418 418.67-0ubuntu1 [104 MB]\n",
      "Get:3 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  nvidia-418-dev 418.67-0ubuntu1 [24.4 kB]\n",
      "Get:4 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  libcuda1-418 418.67-0ubuntu1 [3,803 kB]\n",
      "Get:5 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  nvidia-opencl-icd-418 418.67-0ubuntu1 [3,884 kB]\n",
      "Fetched 112 MB in 2s (53.6 MB/s)                 \n",
      "(Reading database ... 236682 files and directories currently installed.)\n",
      "Removing nvidia-opencl-icd-361 (367.57-0ubuntu0.16.04.1) ...\n",
      "(Reading database ... 236679 files and directories currently installed.)\n",
      "Preparing to unpack .../cuda-drivers_418.67-1_amd64.deb ...\n",
      "Unpacking cuda-drivers (418.67-1) over (367.48-1) ...\n",
      "(Reading database ... 236679 files and directories currently installed.)\n",
      "Removing nvidia-opencl-icd-367 (387.26-0ubuntu1) ...\n",
      "Removing nvidia-opencl-icd-387 (387.26-0ubuntu1) ...\n",
      "Removing nvidia-367-dev (387.26-0ubuntu1) ...\n",
      "Removing nvidia-387-dev (387.26-0ubuntu1) ...\n",
      "dpkg: nvidia-387: dependency problems, but removing anyway as you requested:\n",
      " nvidia-367 depends on nvidia-387.\n",
      " libcuda1-387 depends on nvidia-387 (>= 387.26).\n",
      "\n",
      "Removing nvidia-387 (387.26-0ubuntu1) ...\n",
      "Removing all DKMS Modules\n",
      "Done.\n",
      "update-alternatives: using /usr/lib/nvidia-387-prime/ld.so.conf to provide /etc/ld.so.conf.d/x86_64-linux-gnu_GL.conf (x86_64-linux-gnu_gl_conf) in auto mode\n",
      "update-alternatives: using /usr/lib/nvidia-387-prime/ld.so.conf to provide /etc/ld.so.conf.d/x86_64-linux-gnu_EGL.conf (x86_64-linux-gnu_egl_conf) in auto mode\n",
      "update-alternatives: using /usr/lib/nvidia-387-prime/alt_ld.so.conf to provide /etc/ld.so.conf.d/i386-linux-gnu_GL.conf (i386-linux-gnu_gl_conf) in auto mode\n",
      "update-alternatives: using /usr/lib/nvidia-387-prime/alt_ld.so.conf to provide /etc/ld.so.conf.d/i386-linux-gnu_EGL.conf (i386-linux-gnu_egl_conf) in auto mode\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/mesa/ld.so.conf to provide /etc/ld.so.conf.d/x86_64-linux-gnu_GL.conf (x86_64-linux-gnu_gl_conf) in auto mode\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/mesa-egl/ld.so.conf to provide /etc/ld.so.conf.d/x86_64-linux-gnu_EGL.conf (x86_64-linux-gnu_egl_conf) in auto mode\n",
      "sent invalidate(passwd) request, exiting\n",
      "sent invalidate(group) request, exiting\n",
      "sent invalidate(passwd) request, exiting\n",
      "sent invalidate(group) request, exiting\n",
      "update-initramfs: deferring update (trigger activated)\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11) ...\n",
      "/sbin/ldconfig.real: /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.5 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.6 is not a symbolic link\n",
      "\n",
      "Processing triggers for man-db (2.7.5-1) ...\n",
      "Processing triggers for initramfs-tools (0.122ubuntu8.14) ...\n",
      "update-initramfs: Generating /boot/initrd.img-4.4.0-148-generic\n",
      "W: mdadm: /etc/mdadm/mdadm.conf defines no arrays.\n",
      "Selecting previously unselected package nvidia-418.\n",
      "(Reading database ... 236082 files and directories currently installed.)\n",
      "Preparing to unpack .../nvidia-418_418.67-0ubuntu1_amd64.deb ...\n",
      "Unpacking nvidia-418 (418.67-0ubuntu1) ...\n",
      "Selecting previously unselected package nvidia-418-dev.\n",
      "Preparing to unpack .../nvidia-418-dev_418.67-0ubuntu1_amd64.deb ...\n",
      "Unpacking nvidia-418-dev (418.67-0ubuntu1) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11) ...\n",
      "/sbin/ldconfig.real: /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.5 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.6 is not a symbolic link\n",
      "\n",
      "Processing triggers for ureadahead (0.100.0-19.1) ...\n",
      "Processing triggers for man-db (2.7.5-1) ...\n",
      "(Reading database ... 236720 files and directories currently installed.)\n",
      "Removing libcuda1-367 (387.26-0ubuntu1) ...\n",
      "dpkg: libcuda1-387: dependency problems, but removing anyway as you requested:\n",
      " libcuinj64-7.5:amd64 depends on libcuda1 (>= 352.39) | libcuda-7.5-1; however:\n",
      "  Package libcuda1 is not installed.\n",
      "  Package libcuda-7.5-1 is not installed.\n",
      "  Package libcuda1-387 which provides libcuda-7.5-1 is to be removed.\n",
      "\n",
      "Removing libcuda1-387 (387.26-0ubuntu1) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11) ...\n",
      "/sbin/ldconfig.real: /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.5 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.6 is not a symbolic link\n",
      "\n",
      "Selecting previously unselected package libcuda1-418.\n",
      "(Reading database ... 236707 files and directories currently installed.)\n",
      "Preparing to unpack .../libcuda1-418_418.67-0ubuntu1_amd64.deb ...\n",
      "Unpacking libcuda1-418 (418.67-0ubuntu1) ...\n",
      "Selecting previously unselected package nvidia-opencl-icd-418.\n",
      "Preparing to unpack .../nvidia-opencl-icd-418_418.67-0ubuntu1_amd64.deb ...\n",
      "Unpacking nvidia-opencl-icd-418 (418.67-0ubuntu1) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11) ...\n",
      "/sbin/ldconfig.real: /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.5 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.6 is not a symbolic link\n",
      "\n",
      "(Reading database ... 236724 files and directories currently installed.)\n",
      "Removing nvidia-367 (387.26-0ubuntu1) ...\n",
      "Setting up nvidia-418 (418.67-0ubuntu1) ...\n",
      "update-alternatives: using /usr/lib/nvidia-418/ld.so.conf to provide /etc/ld.so.conf.d/x86_64-linux-gnu_GL.conf (x86_64-linux-gnu_gl_conf) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/grub-gfxpayload-lists/blacklist/10_proprietary-graphics-drivers because associated file /usr/share/nvidia-418/nvidia-418.grub-gfxpayload (of link group x86_64-linux-gnu_gl_conf) doesn't exist\n",
      "update-alternatives: using /usr/lib/nvidia-418/ld.so.conf to provide /etc/ld.so.conf.d/x86_64-linux-gnu_EGL.conf (x86_64-linux-gnu_egl_conf) in auto mode\n",
      "update-alternatives: using /usr/lib/nvidia-418/alt_ld.so.conf to provide /etc/ld.so.conf.d/i386-linux-gnu_GL.conf (i386-linux-gnu_gl_conf) in auto mode\n",
      "update-alternatives: using /usr/lib/nvidia-418/alt_ld.so.conf to provide /etc/ld.so.conf.d/i386-linux-gnu_EGL.conf (i386-linux-gnu_egl_conf) in auto mode\n",
      "update-alternatives: using /usr/share/nvidia-418/glamor.conf to provide /usr/share/X11/xorg.conf.d/glamoregl.conf (glamor_conf) in auto mode\n",
      "/sbin/ldconfig.real: /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.5 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.6 is not a symbolic link\n",
      "\n",
      "update-initramfs: deferring update (trigger activated)\n",
      "update-initramfs: Generating /boot/initrd.img-4.4.0-59-generic\n",
      "W: mdadm: /etc/mdadm/mdadm.conf defines no arrays.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A modprobe blacklist file has been created at /etc/modprobe.d to prevent Nouveau from loading. This can be reverted by deleting /etc/modprobe.d/nvidia-graphics-drivers.conf.\n",
      "A new initrd image has also been created. To revert, please replace /boot/initrd-4.4.0-59-generic with /boot/initrd-$(uname -r)-backup.\n",
      "\n",
      "*****************************************************************************\n",
      "*** Reboot your computer and verify that the NVIDIA graphics driver can   ***\n",
      "*** be loaded.                                                            ***\n",
      "*****************************************************************************\n",
      "\n",
      "Adding system user `nvidia-persistenced' (UID 116) ...\n",
      "sent invalidate(passwd) request, exiting\n",
      "sent invalidate(group) request, exiting\n",
      "Adding new group `nvidia-persistenced' (GID 123) ...\n",
      "sent invalidate(passwd) request, exiting\n",
      "sent invalidate(group) request, exiting\n",
      "sent invalidate(group) request, exiting\n",
      "sent invalidate(group) request, exiting\n",
      "Adding new user `nvidia-persistenced' (UID 116) with group `nvidia-persistenced' ...\n",
      "sent invalidate(passwd) request, exiting\n",
      "sent invalidate(group) request, exiting\n",
      "sent invalidate(passwd) request, exiting\n",
      "sent invalidate(group) request, exiting\n",
      "sent invalidate(passwd) request, exiting\n",
      "sent invalidate(group) request, exiting\n",
      "sent invalidate(passwd) request, exiting\n",
      "sent invalidate(group) request, exiting\n",
      "sent invalidate(passwd) request, exiting\n",
      "sent invalidate(group) request, exiting\n",
      "sent invalidate(passwd) request, exiting\n",
      "sent invalidate(group) request, exiting\n",
      "sent invalidate(passwd) request, exiting\n",
      "sent invalidate(group) request, exiting\n",
      "sent invalidate(passwd) request, exiting\n",
      "Not creating home directory `/'.\n",
      "Loading new nvidia-418-418.67 DKMS files...\n",
      "First Installation: checking all kernels...\n",
      "Building for 4.4.0-59-generic and 4.4.0-148-generic\n",
      "Building for architecture x86_64\n",
      "Building initial module for 4.4.0-59-generic\n",
      "Done.\n",
      "\n",
      "nvidia_418:\n",
      "Running module version sanity check.\n",
      " - Original module\n",
      "   - No original module exists within this kernel\n",
      " - Installation\n",
      "   - Installing to /lib/modules/4.4.0-59-generic/updates/dkms/\n",
      "\n",
      "nvidia_418_modeset.ko:\n",
      "Running module version sanity check.\n",
      " - Original module\n",
      "   - No original module exists within this kernel\n",
      " - Installation\n",
      "   - Installing to /lib/modules/4.4.0-59-generic/updates/dkms/\n",
      "\n",
      "nvidia_418_drm.ko:\n",
      "Running module version sanity check.\n",
      " - Original module\n",
      "   - No original module exists within this kernel\n",
      " - Installation\n",
      "   - Installing to /lib/modules/4.4.0-59-generic/updates/dkms/\n",
      "\n",
      "nvidia_418_uvm.ko:\n",
      "Running module version sanity check.\n",
      " - Original module\n",
      "   - No original module exists within this kernel\n",
      " - Installation\n",
      "   - Installing to /lib/modules/4.4.0-59-generic/updates/dkms/\n",
      "\n",
      "depmod....\n",
      "\n",
      "DKMS: install completed.\n",
      "Building initial module for 4.4.0-148-generic\n",
      "Done.\n",
      "\n",
      "nvidia_418:\n",
      "Running module version sanity check.\n",
      " - Original module\n",
      "   - No original module exists within this kernel\n",
      " - Installation\n",
      "   - Installing to /lib/modules/4.4.0-148-generic/updates/dkms/\n",
      "\n",
      "nvidia_418_modeset.ko:\n",
      "Running module version sanity check.\n",
      " - Original module\n",
      "   - No original module exists within this kernel\n",
      " - Installation\n",
      "   - Installing to /lib/modules/4.4.0-148-generic/updates/dkms/\n",
      "\n",
      "nvidia_418_drm.ko:\n",
      "Running module version sanity check.\n",
      " - Original module\n",
      "   - No original module exists within this kernel\n",
      " - Installation\n",
      "   - Installing to /lib/modules/4.4.0-148-generic/updates/dkms/\n",
      "\n",
      "nvidia_418_uvm.ko:\n",
      "Running module version sanity check.\n",
      " - Original module\n",
      "   - No original module exists within this kernel\n",
      " - Installation\n",
      "   - Installing to /lib/modules/4.4.0-148-generic/updates/dkms/\n",
      "\n",
      "depmod....\n",
      "\n",
      "DKMS: install completed.\n",
      "Setting up nvidia-418-dev (418.67-0ubuntu1) ...\n",
      "Setting up libcuda1-418 (418.67-0ubuntu1) ...\n",
      "Setting up nvidia-opencl-icd-418 (418.67-0ubuntu1) ...\n",
      "Setting up cuda-drivers (418.67-1) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11) ...\n",
      "/sbin/ldconfig.real: /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.5 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.6 is not a symbolic link\n",
      "\n",
      "Processing triggers for initramfs-tools (0.122ubuntu8.14) ...\n",
      "update-initramfs: Generating /boot/initrd.img-4.4.0-148-generic\n",
      "W: mdadm: /etc/mdadm/mdadm.conf defines no arrays.\n"
     ]
    }
   ],
   "source": [
    "! sudo apt-get install cuda-drivers -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata: done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ubuntu/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  pytorch            pytorch/linux-64::pytorch-1.1.0-py3.7_cuda9.0.176_cudnn7.5.1_0\n",
      "  torchvision        pytorch/linux-64::torchvision-0.3.0-py37_cu9.0.176_1\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "! conda install torchvision -c pytorch --y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling torch-1.0.1:\n",
      "  Successfully uninstalled torch-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch --y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: cd: can't cd to cd\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  654M  100  654M    0     0   223M      0  0:00:02  0:00:02 --:--:--  223M\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!cd cd /tmp; curl -O https://repo.anaconda.com/archive/Anaconda3-2019.03-Linux-x86_64.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/de/4f22073f3afa618976ee0721b0deb72b5cde2782057e04a815a6828b53f9/kaggle-1.5.4.tar.gz (54kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 32.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in ./anaconda3/lib/python3.7/site-packages (from kaggle) (1.24.1)\n",
      "Requirement already satisfied: six>=1.10 in ./anaconda3/lib/python3.7/site-packages (from kaggle) (1.12.0)\n",
      "Requirement already satisfied: certifi in ./anaconda3/lib/python3.7/site-packages (from kaggle) (2019.3.9)\n",
      "Requirement already satisfied: python-dateutil in ./anaconda3/lib/python3.7/site-packages (from kaggle) (2.8.0)\n",
      "Requirement already satisfied: requests in ./anaconda3/lib/python3.7/site-packages (from kaggle) (2.21.0)\n",
      "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.7/site-packages (from kaggle) (4.31.1)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading https://files.pythonhosted.org/packages/c1/19/c3cf1dc65e89aa999f85a4a3a4924ccac765a6964b405d487b7b7c8bb39f/python-slugify-3.0.2.tar.gz\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./anaconda3/lib/python3.7/site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./anaconda3/lib/python3.7/site-packages (from requests->kaggle) (2.8)\n",
      "Collecting text-unidecode==1.2 (from python-slugify->kaggle)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/42/d717cc2b4520fb09e45b344b1b0b4e81aa672001dd128c180fabc655c341/text_unidecode-1.2-py2.py3-none-any.whl (77kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 36.6MB/s ta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: kaggle, python-slugify\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ubuntu/.cache/pip/wheels/87/ea/09/173986e395d051411b9d547a69fe96cdc26208cb1bcc3e5567\n",
      "  Building wheel for python-slugify (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ubuntu/.cache/pip/wheels/16/7f/c3/6b0582283ad589d68a306da924a78c74546e010d8106b9b3a9\n",
      "Successfully built kaggle python-slugify\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.4 python-slugify-3.0.2 text-unidecode-1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/52/61b9619a7a95a8d809515f68f1441224a07ce1873fd3af5e662851014a55/opencv_python-4.1.0.25-cp37-cp37m-manylinux1_x86_64.whl (26.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 26.6MB 2.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in ./anaconda3/lib/python3.7/site-packages (from opencv-python) (1.16.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.1.0.25\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: The conda.compat module is deprecated and will be removed in a future release.\n",
      "Collecting package metadata: done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ubuntu/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.6.14               |           py37_0         2.1 MB\n",
      "    cudatoolkit-10.0.130       |                0       380.0 MB\n",
      "    ninja-1.9.0                |   py37hfd86e86_0         1.6 MB\n",
      "    pytorch-1.1.0              |py3.7_cuda10.0.130_cudnn7.5.1_0       455.0 MB  pytorch\n",
      "    torchvision-0.3.0          |py37_cu10.0.130_1         3.7 MB  pytorch\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       842.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.0.130-0\n",
      "  ninja              pkgs/main/linux-64::ninja-1.9.0-py37hfd86e86_0\n",
      "  pytorch            pytorch/linux-64::pytorch-1.1.0-py3.7_cuda10.0.130_cudnn7.5.1_0\n",
      "  torchvision        pytorch/linux-64::torchvision-0.3.0-py37_cu10.0.130_1\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                                       4.6.11-py37_0 --> 4.6.14-py37_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "conda-4.6.14         | 2.1 MB    | ##################################### | 100% \n",
      "cudatoolkit-10.0.130 | 380.0 MB  | ##################################### | 100% \n",
      "ninja-1.9.0          | 1.6 MB    | ##################################### | 100% \n",
      "torchvision-0.3.0    | 3.7 MB    | ##################################### | 100% \n",
      "pytorch-1.1.0        | 455.0 MB  | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c pytorch torchvision --yes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/cu80/stable\n",
      "Collecting torch==1.0.1\n",
      "  Using cached https://files.pythonhosted.org/packages/4e/ba/d78f35357995297206790fe1af8688bc0403828c90f8e99190035196d56e/torch-1.0.1-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.0.1 -f https://download.pytorch.org/whl/cu80/stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from tqdm import tqdm_notebook\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lost+found\t\t   test.csv\t test_images.zip  train_images\r\n",
      "sample_submission.csv\t   test.csv.zip  train.csv\t  train_images.zip\r\n",
      "sample_submission.csv.zip  test_images\t train.csv.zip\r\n"
     ]
    }
   ],
   "source": [
    "! cd /; cd data; ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggle_commit_logger(str_to_log, need_print = True):\n",
    "    if need_print:\n",
    "        print(str_to_log)\n",
    "    os.system('echo ' + str_to_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>date_captured</th>\n",
       "      <th>file_name</th>\n",
       "      <th>frame_num</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>rights_holder</th>\n",
       "      <th>seq_id</th>\n",
       "      <th>seq_num_frames</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>2011-05-13 23:43:18</td>\n",
       "      <td>5998cfa4-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>5998cfa4-23d2-11e8-a6a3-ec086b02610b</td>\n",
       "      <td>33</td>\n",
       "      <td>Justin Brown</td>\n",
       "      <td>6f084ccc-5567-11e8-bc84-dca9047ef277</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>2012-03-17 03:48:44</td>\n",
       "      <td>588a679f-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>588a679f-23d2-11e8-a6a3-ec086b02610b</td>\n",
       "      <td>115</td>\n",
       "      <td>Justin Brown</td>\n",
       "      <td>6f12067d-5567-11e8-b3c0-dca9047ef277</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-05-11 11:56:46</td>\n",
       "      <td>59279ce3-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>59279ce3-23d2-11e8-a6a3-ec086b02610b</td>\n",
       "      <td>96</td>\n",
       "      <td>Erin Boydston</td>\n",
       "      <td>6faa92d1-5567-11e8-b1ae-dca9047ef277</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-10-06 02:00:00</td>\n",
       "      <td>5a2af4ab-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>5a2af4ab-23d2-11e8-a6a3-ec086b02610b</td>\n",
       "      <td>57</td>\n",
       "      <td>Erin Boydston</td>\n",
       "      <td>6f7d4702-5567-11e8-9e03-dca9047ef277</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2011-07-12 13:11:16</td>\n",
       "      <td>599fbd89-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>599fbd89-23d2-11e8-a6a3-ec086b02610b</td>\n",
       "      <td>46</td>\n",
       "      <td>Justin Brown</td>\n",
       "      <td>6f1728a1-5567-11e8-9be7-dca9047ef277</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id        date_captured                                 file_name  \\\n",
       "0           19  2011-05-13 23:43:18  5998cfa4-23d2-11e8-a6a3-ec086b02610b.jpg   \n",
       "1           19  2012-03-17 03:48:44  588a679f-23d2-11e8-a6a3-ec086b02610b.jpg   \n",
       "2            0  2014-05-11 11:56:46  59279ce3-23d2-11e8-a6a3-ec086b02610b.jpg   \n",
       "3            0  2013-10-06 02:00:00  5a2af4ab-23d2-11e8-a6a3-ec086b02610b.jpg   \n",
       "4            0  2011-07-12 13:11:16  599fbd89-23d2-11e8-a6a3-ec086b02610b.jpg   \n",
       "\n",
       "   frame_num                                    id  location  rights_holder  \\\n",
       "0          1  5998cfa4-23d2-11e8-a6a3-ec086b02610b        33   Justin Brown   \n",
       "1          2  588a679f-23d2-11e8-a6a3-ec086b02610b       115   Justin Brown   \n",
       "2          1  59279ce3-23d2-11e8-a6a3-ec086b02610b        96  Erin Boydston   \n",
       "3          1  5a2af4ab-23d2-11e8-a6a3-ec086b02610b        57  Erin Boydston   \n",
       "4          3  599fbd89-23d2-11e8-a6a3-ec086b02610b        46   Justin Brown   \n",
       "\n",
       "                                 seq_id  seq_num_frames  width  height  \n",
       "0  6f084ccc-5567-11e8-bc84-dca9047ef277               3   1024     747  \n",
       "1  6f12067d-5567-11e8-b3c0-dca9047ef277               3   1024     747  \n",
       "2  6faa92d1-5567-11e8-b1ae-dca9047ef277               1   1024     747  \n",
       "3  6f7d4702-5567-11e8-9e03-dca9047ef277               1   1024     747  \n",
       "4  6f1728a1-5567-11e8-9be7-dca9047ef277               3   1024     747  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_all = pd.read_csv('/data/train.csv',engine='python',)\n",
    "train_df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "IMG_SIZE = 64\n",
    "N_EPOCHS = 15\n",
    "ID_COLNAME = 'file_name'\n",
    "ANSWER_COLNAME = 'category_id'\n",
    "TRAIN_IMGS_DIR = '/data/train_images/'\n",
    "TEST_IMGS_DIR = '/data/test_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(train_df_all[[ID_COLNAME, ANSWER_COLNAME]],\n",
    "                                     test_size = 0.15,                                     \n",
    "                                     shuffle = True\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49489</th>\n",
       "      <td>58995a6f-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26272</th>\n",
       "      <td>59373297-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>5a2e12d8-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39707</th>\n",
       "      <td>5892b3ca-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177608</th>\n",
       "      <td>5a2e14a1-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48844</th>\n",
       "      <td>58e40ec2-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143147</th>\n",
       "      <td>59da8b75-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33424</th>\n",
       "      <td>597fef49-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153633</th>\n",
       "      <td>58f73fbb-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61932</th>\n",
       "      <td>5a2637ee-23d2-11e8-a6a3-ec086b02610b.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       file_name  category_id\n",
       "49489   58995a6f-23d2-11e8-a6a3-ec086b02610b.jpg            0\n",
       "26272   59373297-23d2-11e8-a6a3-ec086b02610b.jpg            0\n",
       "841     5a2e12d8-23d2-11e8-a6a3-ec086b02610b.jpg            0\n",
       "39707   5892b3ca-23d2-11e8-a6a3-ec086b02610b.jpg            0\n",
       "177608  5a2e14a1-23d2-11e8-a6a3-ec086b02610b.jpg           19\n",
       "48844   58e40ec2-23d2-11e8-a6a3-ec086b02610b.jpg            3\n",
       "143147  59da8b75-23d2-11e8-a6a3-ec086b02610b.jpg           19\n",
       "33424   597fef49-23d2-11e8-a6a3-ec086b02610b.jpg            0\n",
       "153633  58f73fbb-23d2-11e8-a6a3-ec086b02610b.jpg            0\n",
       "61932   5a2637ee-23d2-11e8-a6a3-ec086b02610b.jpg            4"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES_TO_USE = train_df_all['category_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19,  0,  3,  8,  4, 13,  1, 11, 16, 17, 14, 18, 10, 22])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASSES_TO_USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(CLASSES_TO_USE)\n",
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{19: 0,\n",
       " 0: 1,\n",
       " 3: 2,\n",
       " 8: 3,\n",
       " 4: 4,\n",
       " 13: 5,\n",
       " 1: 6,\n",
       " 11: 7,\n",
       " 16: 8,\n",
       " 17: 9,\n",
       " 14: 10,\n",
       " 18: 11,\n",
       " 10: 12,\n",
       " 22: 13}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASSMAP = dict(\n",
    "    [(i, j) for i, j\n",
    "     in zip(CLASSES_TO_USE, range(NUM_CLASSES))\n",
    "    ]\n",
    ")\n",
    "CLASSMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 19,\n",
       " 1: 0,\n",
       " 2: 3,\n",
       " 3: 8,\n",
       " 4: 4,\n",
       " 5: 13,\n",
       " 6: 1,\n",
       " 7: 11,\n",
       " 8: 16,\n",
       " 9: 17,\n",
       " 10: 14,\n",
       " 11: 18,\n",
       " 12: 10,\n",
       " 13: 22}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REVERSE_CLASSMAP = dict([(v, k) for k, v in CLASSMAP.items()])\n",
    "REVERSE_CLASSMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extract = False\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained='imagenet')\n",
    "#model = models.densenet121(pretrained='imagenet')\n",
    "set_parameter_requires_grad(model, feature_extract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 1000)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc.in_features,model.fc.out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc.out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_head = torch.nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "model.fc = new_head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_augmentation = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    normalizer,\n",
    "])\n",
    "\n",
    "val_augmentation = transforms.Compose([\n",
    "    #transforms.CenterCrop(IMG_SIZE),\n",
    "\n",
    "    transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    normalizer,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMetDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 df,\n",
    "                 images_dir,\n",
    "                 n_classes = NUM_CLASSES,\n",
    "                 id_colname = ID_COLNAME,\n",
    "                 answer_colname = ANSWER_COLNAME,\n",
    "                 label_dict = CLASSMAP,\n",
    "                 transforms = None\n",
    "                ):\n",
    "        self.df = df\n",
    "        self.images_dir = images_dir\n",
    "        self.n_classes = n_classes\n",
    "        self.id_colname = id_colname\n",
    "        self.answer_colname = answer_colname\n",
    "        self.label_dict = label_dict\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        cur_idx_row = self.df.iloc[idx]\n",
    "        img_id = cur_idx_row[self.id_colname]\n",
    "        img_name = img_id # + self.img_ext\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        \n",
    "        img = cv2.imread(img_path)\n",
    "        #print('HERE ', img_path)\n",
    "#         print(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(img)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        \n",
    "        if self.answer_colname is not None:              \n",
    "            label = torch.zeros((self.n_classes,), dtype=torch.float32)\n",
    "            label[self.label_dict[cur_idx_row[self.answer_colname]]] = 1.0\n",
    "\n",
    "            return img, label\n",
    "        \n",
    "        else:\n",
    "            return img, img_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IMetDataset(train_df, TRAIN_IMGS_DIR, transforms = train_augmentation)\n",
    "test_dataset = IMetDataset(test_df, TRAIN_IMGS_DIR, transforms = val_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 24\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda(x):\n",
    "    #return x\n",
    "    return x.cuda(non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def F_score(logit, label, threshold=0.5, beta=2):\n",
    "    prob = torch.sigmoid(logit)\n",
    "    prob = prob > threshold\n",
    "    label = label > threshold\n",
    "\n",
    "    TP = (prob & label).sum(1).float()\n",
    "    TN = ((~prob)& (~label)).sum(1).float()\n",
    "    FP = (prob & (~label)).sum(1).float()\n",
    "    FN = ((~prob) & label).sum(1).float()\n",
    "\n",
    "    precision = torch.mean(TP / (TP + FP + 1e-12))\n",
    "    recall = torch.mean(TP / (TP + FN + 1e-12))\n",
    "    F2 = (1 + beta**2) * precision * recall / (beta**2 * precision + recall + 1e-12)\n",
    "    return F2.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred, threshold=0.5):\n",
    "    return fbeta_score(y_true, y_pred, 1, threshold)\n",
    "\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta, threshold, eps=1e-9):\n",
    "    beta2 = beta**2\n",
    "\n",
    "    y_pred = torch.ge(y_pred.float(), threshold).float()\n",
    "    y_true = y_true.float()\n",
    "\n",
    "    true_positive = (y_pred * y_true).sum(dim=1)\n",
    "    precision = true_positive.div(y_pred.sum(dim=1).add(eps))\n",
    "    recall = true_positive.div(y_true.sum(dim=1).add(eps))\n",
    "\n",
    "    return torch.mean(\n",
    "        (precision*recall).\n",
    "        div(precision.mul(beta2) + recall + eps).\n",
    "        mul(1 + beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, steps_upd_logging = 250):\n",
    "    model.train();\n",
    "    model = model.to(device)\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    \n",
    "    train_tqdm = tqdm_notebook(train_loader)\n",
    "    \n",
    "    for step, (features, targets) in enumerate(train_tqdm):\n",
    "#        features, targets = cuda(features), cuda(targets)\n",
    "        features, targets = features.to(device), targets.to(device) \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(features)\n",
    "        \n",
    "        loss = criterion(logits, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if (step + 1) % steps_upd_logging == 0:\n",
    "            logstr = \"Train loss on step \"+ str(step + 1)+' was '+str(round(total_loss / (step + 1), 5))\n",
    "            #logstr = f\"Train loss on step {step + 1} was {round(total_loss / (step + 1), 5)}\"\n",
    "            train_tqdm.set_description(logstr)\n",
    "            kaggle_commit_logger(logstr, need_print=False)\n",
    "        \n",
    "    return total_loss / (step + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valid_loader, criterion, need_tqdm = False):\n",
    "    model.eval();\n",
    "    model = model.to(device)\n",
    "    test_loss = 0.0\n",
    "    TH_TO_ACC = 0.5\n",
    "    \n",
    "    true_ans_list = []\n",
    "    preds_cat = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        if need_tqdm:\n",
    "            valid_iterator = tqdm_notebook(valid_loader)\n",
    "        else:\n",
    "            valid_iterator = valid_loader\n",
    "        \n",
    "        for step, (features, targets) in enumerate(valid_iterator):\n",
    "            #features, targets = cuda(features), cuda(targets)\n",
    "            features, targets = features.to(device), targets.to(device) \n",
    "            logits = model(features)\n",
    "            loss = criterion(logits, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            true_ans_list.append(targets)\n",
    "            preds_cat.append(torch.sigmoid(logits))\n",
    "\n",
    "        all_true_ans = torch.cat(true_ans_list)\n",
    "        all_preds = torch.cat(preds_cat)\n",
    "                \n",
    "        f1_eval = f1_score(all_true_ans, all_preds).item()\n",
    "\n",
    "    logstr = 'Mean val f1: '+str(round(f1_eval, 5))\n",
    "    kaggle_commit_logger(logstr)\n",
    "    return test_loss / (step + 1), f1_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "sheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 epoch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311f43e1779a4adebb5960d81aab73a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6953), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean train loss: 0.11177\n",
      "Mean val f1: 0.62861\n",
      "Mean valid loss: 0.09294\n",
      "Starting 2 epoch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f314a767faca44e494219be2a35c47d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6953), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean train loss: 0.09693\n",
      "Mean val f1: 0.64614\n",
      "Mean valid loss: 0.08184\n",
      "Starting 3 epoch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f708419f48141f1806563fc55b427de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6953), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean train loss: 0.0903\n",
      "Mean val f1: 0.6506\n",
      "Mean valid loss: 0.07649\n",
      "Starting 4 epoch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20cf439840b14a14811bc6077c7bfbee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6953), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean train loss: 0.08555\n",
      "Mean val f1: 0.69413\n",
      "Mean valid loss: 0.07181\n",
      "Starting 5 epoch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544ab93d3b4a4b1e8bb9a0498a1cb7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6953), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean train loss: 0.08228\n",
      "Mean val f1: 0.70627\n",
      "Mean valid loss: 0.0732\n",
      "Starting 6 epoch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651cf8be70b74be6be26608d5e6247c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6953), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean train loss: 0.07976\n",
      "Mean val f1: 0.72389\n",
      "Mean valid loss: 0.06744\n",
      "Starting 7 epoch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359d63166d6f430685483f52df538eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6953), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean train loss: 0.07752\n",
      "Mean val f1: 0.70721\n",
      "Mean valid loss: 0.06768\n",
      "Starting 8 epoch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96faeb46fe4e4566ab6e36ec1dcb4090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6953), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean train loss: 0.07567\n",
      "Mean val f1: 0.72894\n",
      "Mean valid loss: 0.06402\n",
      "Starting 9 epoch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6936ac961d384e238b142c6199aec6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6953), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean train loss: 0.07423\n",
      "Mean val f1: 0.73509\n",
      "Mean valid loss: 0.06238\n",
      "Starting 10 epoch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4a219e3d514c20a20a57cfc309f3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6953), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean train loss: 0.07271\n",
      "Mean val f1: 0.72027\n",
      "Mean valid loss: 0.07191\n",
      "Starting 11 epoch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab8d504e50d4382915955763e2a022a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6953), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean train loss: 0.0716\n",
      "Mean val f1: 0.74774\n",
      "Mean valid loss: 0.06269\n",
      "Starting 12 epoch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9be1fa6f604d9a824ed6ceb644390a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6953), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean train loss: 0.07051\n",
      "Mean val f1: 0.72224\n",
      "Mean valid loss: 0.08041\n",
      "Starting 13 epoch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158e2a8d6e1544d998cb596713ab3b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6953), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean train loss: 0.06942\n",
      "Mean val f1: 0.7257\n",
      "Mean valid loss: 0.08694\n",
      "Starting 14 epoch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d840d0fc590e4b828eaba8bf3c91febb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6953), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean train loss: 0.0685\n",
      "Mean val f1: 0.76174\n",
      "Mean valid loss: 0.05824\n",
      "Starting 15 epoch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52fb89b61fbf4139a5557cf44d4c2a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6953), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean train loss: 0.06775\n",
      "Mean val f1: 0.76536\n",
      "Mean valid loss: 0.0568\n"
     ]
    }
   ],
   "source": [
    "TRAIN_LOGGING_EACH = 500\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "valid_f1s = []\n",
    "best_model_f1 = 0.0\n",
    "best_model = None\n",
    "best_model_ep = 0\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    ep_logstr = \"Starting \"+str(epoch)+\" epoch...\"\n",
    "    kaggle_commit_logger(ep_logstr)\n",
    "    tr_loss = train_one_epoch(model, train_loader, criterion, optimizer, TRAIN_LOGGING_EACH)\n",
    "    train_losses.append(tr_loss)\n",
    "    tr_loss_logstr = 'Mean train loss: '+str(round(tr_loss,5))\n",
    "    kaggle_commit_logger(tr_loss_logstr)\n",
    "    \n",
    "    valid_loss, valid_f1 = validate(model, test_loader, criterion)  \n",
    "    valid_losses.append(valid_loss)    \n",
    "    valid_f1s.append(valid_f1)       \n",
    "    val_loss_logstr = 'Mean valid loss: '+str(round(valid_loss,5))\n",
    "    kaggle_commit_logger(val_loss_logstr)\n",
    "    sheduler.step(valid_loss)\n",
    "    \n",
    "    if valid_f1 >= best_model_f1:    \n",
    "        best_model = model        \n",
    "        best_model_f1 = valid_f1        \n",
    "        best_model_ep = epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1 is 0.76536 on epoch 15\n"
     ]
    }
   ],
   "source": [
    "bestmodel_logstr = f'Best f1 is {round(best_model_f1, 5)} on epoch {best_model_ep}'\n",
    "kaggle_commit_logger(bestmodel_logstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = list(range(1, len(train_losses) + 1))\n",
    "\n",
    "plt.plot(xs, train_losses, label = 'Train loss');\n",
    "# plt.plot(xs, valid_losses, label = 'Val loss');\n",
    "plt.plot(xs, valid_f1s, label = 'Val f1');\n",
    "plt.legend();\n",
    "plt.xticks(xs);\n",
    "plt.xlabel('Epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b005e5b2-2c0b-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f2347cfe-2c11-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27cf8d26-2c0e-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f82f52c7-2c1d-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e133f50d-2c1c-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id  Predicted\n",
       "0  b005e5b2-2c0b-11e9-bcad-06f10d5896c4          0\n",
       "1  f2347cfe-2c11-11e9-bcad-06f10d5896c4          0\n",
       "2  27cf8d26-2c0e-11e9-bcad-06f10d5896c4          0\n",
       "3  f82f52c7-2c1d-11e9-bcad-06f10d5896c4          0\n",
       "4  e133f50d-2c1c-11e9-bcad-06f10d5896c4          0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLE_SUBMISSION_DF = pd.read_csv('/data/sample_submission.csv',engine='python')\n",
    "SAMPLE_SUBMISSION_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b005e5b2-2c0b-11e9-bcad-06f10d5896c4.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f2347cfe-2c11-11e9-bcad-06f10d5896c4.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27cf8d26-2c0e-11e9-bcad-06f10d5896c4.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f82f52c7-2c1d-11e9-bcad-06f10d5896c4.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e133f50d-2c1c-11e9-bcad-06f10d5896c4.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  file_name  category_id\n",
       "0  b005e5b2-2c0b-11e9-bcad-06f10d5896c4.jpg            0\n",
       "1  f2347cfe-2c11-11e9-bcad-06f10d5896c4.jpg            0\n",
       "2  27cf8d26-2c0e-11e9-bcad-06f10d5896c4.jpg            0\n",
       "3  f82f52c7-2c1d-11e9-bcad-06f10d5896c4.jpg            0\n",
       "4  e133f50d-2c1c-11e9-bcad-06f10d5896c4.jpg            0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLE_SUBMISSION_DF.rename(columns={'Id':'file_name','Predicted':'category_id'}, inplace=True)\n",
    "SAMPLE_SUBMISSION_DF['file_name'] = SAMPLE_SUBMISSION_DF['file_name'] + '.jpg'\n",
    "SAMPLE_SUBMISSION_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_dataset = IMetDataset(SAMPLE_SUBMISSION_DF,\n",
    "                           TEST_IMGS_DIR,\n",
    "                           transforms = val_augmentation,\n",
    "                           answer_colname=None\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMB_BS = 48\n",
    "\n",
    "subm_dataloader = DataLoader(subm_dataset,\n",
    "                             batch_size=SUMB_BS, num_workers=4,\n",
    "                             shuffle=False,\n",
    "                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subm_answers(model, subm_dataloader, need_tqdm = False):\n",
    "    model.eval();\n",
    "    preds_cat = []\n",
    "    ids = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        if need_tqdm:\n",
    "            subm_iterator = tqdm_notebook(subm_dataloader)\n",
    "        else:\n",
    "            subm_iterator = subm_dataloader\n",
    "        \n",
    "        for step, (features, subm_ids) in enumerate(subm_iterator):\n",
    "            features = cuda(features)\n",
    "\n",
    "            logits = model(features)\n",
    "            preds_cat.append(torch.sigmoid(logits))\n",
    "            ids += subm_ids\n",
    "\n",
    "        all_preds = torch.cat(preds_cat)\n",
    "        all_preds = torch.argmax(all_preds, dim=1).int().cpu().numpy()\n",
    "    return all_preds, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9483477e5d1c453b8040dde4e2dafe4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3203), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_model.cuda();\n",
    "\n",
    "subm_preds, submids = get_subm_answers(best_model, subm_dataloader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153730"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subm_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_dict = dict(zip(submids, subm_preds.astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b005e5b2-2c0b-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f2347cfe-2c11-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27cf8d26-2c0e-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f82f52c7-2c1d-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e133f50d-2c1c-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id Predicted\n",
       "0  b005e5b2-2c0b-11e9-bcad-06f10d5896c4         1\n",
       "1  f2347cfe-2c11-11e9-bcad-06f10d5896c4         6\n",
       "2  27cf8d26-2c0e-11e9-bcad-06f10d5896c4         1\n",
       "3  f82f52c7-2c1d-11e9-bcad-06f10d5896c4         1\n",
       "4  e133f50d-2c1c-11e9-bcad-06f10d5896c4         1"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_process = (\n",
    "    pd.DataFrame\n",
    "    .from_dict(ans_dict, orient='index', columns=['Predicted'])\n",
    "    .reset_index()\n",
    "    .rename({'index':'Id'}, axis=1)    \n",
    ")\n",
    "df_to_process['Id'] = df_to_process['Id'].map(lambda x: str(x)[:-4])\n",
    "df_to_process.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_id(id_classes_str):\n",
    "    if id_classes_str:\n",
    "        return REVERSE_CLASSMAP[int(id_classes_str)]\n",
    "    else:\n",
    "        return id_classes_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b005e5b2-2c0b-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f2347cfe-2c11-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27cf8d26-2c0e-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f82f52c7-2c1d-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e133f50d-2c1c-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id  Predicted\n",
       "0  b005e5b2-2c0b-11e9-bcad-06f10d5896c4          0\n",
       "1  f2347cfe-2c11-11e9-bcad-06f10d5896c4          1\n",
       "2  27cf8d26-2c0e-11e9-bcad-06f10d5896c4          0\n",
       "3  f82f52c7-2c1d-11e9-bcad-06f10d5896c4          0\n",
       "4  e133f50d-2c1c-11e9-bcad-06f10d5896c4          0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_process['Predicted'] = df_to_process['Predicted'].apply(process_one_id)\n",
    "df_to_process.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_process.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- from torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        \n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "              \n",
    "              #  running_corrects += torch.sum(preds == labels.data)\n",
    "                running_corrects+=1\n",
    "            if phase == 'val':\n",
    "                sheduler.step(loss)\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "            \n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extract = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet50(pretrained=True)\n",
    "set_parameter_requires_grad(model_ft, feature_extract)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = torch.nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "#input_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.0.conv3.weight\n",
      "\t layer1.0.bn3.weight\n",
      "\t layer1.0.bn3.bias\n",
      "\t layer1.0.downsample.0.weight\n",
      "\t layer1.0.downsample.1.weight\n",
      "\t layer1.0.downsample.1.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer1.1.conv3.weight\n",
      "\t layer1.1.bn3.weight\n",
      "\t layer1.1.bn3.bias\n",
      "\t layer1.2.conv1.weight\n",
      "\t layer1.2.bn1.weight\n",
      "\t layer1.2.bn1.bias\n",
      "\t layer1.2.conv2.weight\n",
      "\t layer1.2.bn2.weight\n",
      "\t layer1.2.bn2.bias\n",
      "\t layer1.2.conv3.weight\n",
      "\t layer1.2.bn3.weight\n",
      "\t layer1.2.bn3.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.conv3.weight\n",
      "\t layer2.0.bn3.weight\n",
      "\t layer2.0.bn3.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer2.1.conv3.weight\n",
      "\t layer2.1.bn3.weight\n",
      "\t layer2.1.bn3.bias\n",
      "\t layer2.2.conv1.weight\n",
      "\t layer2.2.bn1.weight\n",
      "\t layer2.2.bn1.bias\n",
      "\t layer2.2.conv2.weight\n",
      "\t layer2.2.bn2.weight\n",
      "\t layer2.2.bn2.bias\n",
      "\t layer2.2.conv3.weight\n",
      "\t layer2.2.bn3.weight\n",
      "\t layer2.2.bn3.bias\n",
      "\t layer2.3.conv1.weight\n",
      "\t layer2.3.bn1.weight\n",
      "\t layer2.3.bn1.bias\n",
      "\t layer2.3.conv2.weight\n",
      "\t layer2.3.bn2.weight\n",
      "\t layer2.3.bn2.bias\n",
      "\t layer2.3.conv3.weight\n",
      "\t layer2.3.bn3.weight\n",
      "\t layer2.3.bn3.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.conv3.weight\n",
      "\t layer3.0.bn3.weight\n",
      "\t layer3.0.bn3.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer3.1.conv3.weight\n",
      "\t layer3.1.bn3.weight\n",
      "\t layer3.1.bn3.bias\n",
      "\t layer3.2.conv1.weight\n",
      "\t layer3.2.bn1.weight\n",
      "\t layer3.2.bn1.bias\n",
      "\t layer3.2.conv2.weight\n",
      "\t layer3.2.bn2.weight\n",
      "\t layer3.2.bn2.bias\n",
      "\t layer3.2.conv3.weight\n",
      "\t layer3.2.bn3.weight\n",
      "\t layer3.2.bn3.bias\n",
      "\t layer3.3.conv1.weight\n",
      "\t layer3.3.bn1.weight\n",
      "\t layer3.3.bn1.bias\n",
      "\t layer3.3.conv2.weight\n",
      "\t layer3.3.bn2.weight\n",
      "\t layer3.3.bn2.bias\n",
      "\t layer3.3.conv3.weight\n",
      "\t layer3.3.bn3.weight\n",
      "\t layer3.3.bn3.bias\n",
      "\t layer3.4.conv1.weight\n",
      "\t layer3.4.bn1.weight\n",
      "\t layer3.4.bn1.bias\n",
      "\t layer3.4.conv2.weight\n",
      "\t layer3.4.bn2.weight\n",
      "\t layer3.4.bn2.bias\n",
      "\t layer3.4.conv3.weight\n",
      "\t layer3.4.bn3.weight\n",
      "\t layer3.4.bn3.bias\n",
      "\t layer3.5.conv1.weight\n",
      "\t layer3.5.bn1.weight\n",
      "\t layer3.5.bn1.bias\n",
      "\t layer3.5.conv2.weight\n",
      "\t layer3.5.bn2.weight\n",
      "\t layer3.5.bn2.bias\n",
      "\t layer3.5.conv3.weight\n",
      "\t layer3.5.bn3.weight\n",
      "\t layer3.5.bn3.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.conv3.weight\n",
      "\t layer4.0.bn3.weight\n",
      "\t layer4.0.bn3.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t layer4.1.conv3.weight\n",
      "\t layer4.1.bn3.weight\n",
      "\t layer4.1.bn3.bias\n",
      "\t layer4.2.conv1.weight\n",
      "\t layer4.2.bn1.weight\n",
      "\t layer4.2.bn1.bias\n",
      "\t layer4.2.conv2.weight\n",
      "\t layer4.2.bn2.weight\n",
      "\t layer4.2.bn2.bias\n",
      "\t layer4.2.conv3.weight\n",
      "\t layer4.2.bn3.weight\n",
      "\t layer4.2.bn3.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to('cuda')\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dict = {}\n",
    "dataloaders_dict['train'] = train_loader\n",
    "dataloaders_dict['test'] = test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-2011eec6f87c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_inception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-73-e6afa3cceae1>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, num_epochs, is_inception)\u001b[0m\n\u001b[1;32m     43\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloss2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "sheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3)\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer, num_epochs=N_EPOCHS, is_inception=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
